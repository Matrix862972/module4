{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c5b4aba",
   "metadata": {},
   "source": [
    "# U-Net for Image Segmentation using Oxford Pets Dataset\n",
    "This is a simplified version of the U-Net segmentation model using TensorFlow and Keras, adapted from Andrew Ng's lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-datasets matplotlib -q\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea734c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "def normalize_img(datapoint):\n",
    "    image = tf.cast(datapoint['image'], tf.float32) / 255.0\n",
    "    mask = tf.cast(datapoint['segmentation_mask'], tf.uint8)\n",
    "    mask = mask - 1  # Convert to {0, 1} from {1, 2}\n",
    "    mask = tf.where(mask == 255, 1, mask)  # Fix borders\n",
    "    return image, mask\n",
    "\n",
    "train_dataset = train_dataset.map(normalize_img).cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(normalize_img).batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7338de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def unet_model(input_size=(128, 128, 3)):\n",
    "    inputs = tf.keras.Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D()(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D()(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, 3, activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D()(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    c4 = layers.Conv2D(512, 3, activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, 3, activation='relu', padding='same')(c4)\n",
    "\n",
    "    # Decoder\n",
    "    u5 = layers.UpSampling2D()(c4)\n",
    "    u5 = layers.Concatenate()([u5, c3])\n",
    "    c5 = layers.Conv2D(256, 3, activation='relu', padding='same')(u5)\n",
    "    c5 = layers.Conv2D(256, 3, activation='relu', padding='same')(c5)\n",
    "\n",
    "    u6 = layers.UpSampling2D()(c5)\n",
    "    u6 = layers.Concatenate()([u6, c2])\n",
    "    c6 = layers.Conv2D(128, 3, activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(128, 3, activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.UpSampling2D()(c6)\n",
    "    u7 = layers.Concatenate()([u7, c1])\n",
    "    c7 = layers.Conv2D(64, 3, activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(64, 3, activation='relu', padding='same')(c7)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c7)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = unet_model()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d486741",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "\n",
    "def resize(input_image, input_mask):\n",
    "    input_image = tf.image.resize(input_image, (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(input_mask[..., tf.newaxis], (IMG_SIZE, IMG_SIZE))\n",
    "    return input_image, input_mask\n",
    "\n",
    "train_dataset = train_dataset.map(resize)\n",
    "test_dataset = test_dataset.map(resize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2447001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "model.fit(train_dataset, validation_data=test_dataset, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08beff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for image, mask in test_dataset.take(1):\n",
    "    pred_mask = model.predict(image)\n",
    "    pred_mask = tf.round(pred_mask)\n",
    "    for i in range(3):\n",
    "        display([image[i], mask[i], pred_mask[i]])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
